{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 128\n",
    "LAYER = 2\n",
    "EPOCHS = 100\n",
    "FIELDS = 128\n",
    "USE_GPU = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BusDataset(Dataset):\n",
    "    def __init__(self, is_train_set=True):\n",
    "        # group: 1-29 r error, 29-103 r normal.\n",
    "        df = pd.read_csv('./full_limit.csv')\n",
    "        if is_train_set:\n",
    "            df = pd.concat([df[df['group'] < 22], df[df['group'] > 80]])\n",
    "        else:\n",
    "            df = df[(df['group'] > 21) & (df['group'] < 81)]\n",
    "        ls = np.array(df)\n",
    "        self.data = ls\n",
    "        self.len = ls.shape[0]\n",
    "        self.dataLen =  ls.shape[1] - 2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index > self.len - FIELDS:\n",
    "            print(\"Error: index too great\")\n",
    "            return self.__getitem__(random.randint(0, self.len-FIELDS))\n",
    "        if self.data[index - FIELDS, 0] != self.data[index, 0]:\n",
    "            print(\"Error: not same sample\")\n",
    "            return self.__getitem__(random.randint(0, self.len-FIELDS))\n",
    "        return self.data[index - FIELDS: index, 1:-1], 1.0 if 1.0 in self.data[index - FIELDS: index, -1] else 2.0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def getErrorDict(self):\n",
    "        return {'error': 1.0, 'normal': 2.0}\n",
    "\n",
    "    def index2label(self, index):\n",
    "        dic = {1.0: 'error', 2.0: 'normal'}\n",
    "        return dic[index]\n",
    "    \n",
    "    def getErrorNum(self):\n",
    "        return 2\n",
    "\n",
    "def makeTensors(data,label):\n",
    "    # if(len(data)<101):\n",
    "    #     return torch.tensor(), torch.tensor()\n",
    "    # dataLs = []\n",
    "    # for i in len(data):\n",
    "    #     dataLs.append(data[i, i+FIELDS, 1:-1])\n",
    "    # sequenceData = torch.from_numpy(data)\n",
    "    sequenceData = torch.from_numpy(data)\n",
    "    resultData = torch.from_numpy(label)\n",
    "    return createTensor(sequenceData), createTensor(resultData)\n",
    "\n",
    "def createTensor(tensor):  # 是否使用GPU\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        tensor = tensor.to(device)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "trainset = BusDataset(is_train_set=True)  # train数据\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "testset = BusDataset(is_train_set=False)  # test数据\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "ErrorTypes = trainset.getErrorNum() # 这个就是总的类别的数量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "\n",
    "        # self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "\n",
    "    def __init__hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)\n",
    "        return createTensor(hidden)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input shape:B * S -> S * B\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1)\n",
    "        hidden = self.__init__hidden(batch_size)\n",
    "        # embedding = self.embedding(input)\n",
    "\n",
    "        # # pack them up\n",
    "        # gru_input = pack_padded_sequence(embedding, seq_lengths)\n",
    "\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    total_loss = 0\n",
    "    for i, (names, countries) in enumerate(trainloader, 1):\n",
    "        inputs, target = makeTensors(names, countries)\n",
    "        output = classifier(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch}', end='')\n",
    "            print(f'[{i * len(inputs)}/{len(trainset)}]', end='')\n",
    "            print(f'loss={total_loss / (i * len(inputs))}')\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print(\"evaluating trained model...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(testloader, 1):\n",
    "            inputs, seq_lengths, target = makeTensors(names, countries)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        percent = '%.2f' % (100 * correct / total)\n",
    "        print(f'Test set:Accuracy{correct} / {total} {percent}%')\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    classifier = RNNClassifier(HIDDEN_SIZE, ErrorTypes, LAYER)\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        classifier.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"Training for %d epochs...\" % EPOCHS)\n",
    "    acc_list = []\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        trainModel()\n",
    "        acc = testModel()\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    epoch = np.arange(1, len(acc_list) + 1, 1)\n",
    "    acc_list = np.array(acc_list)\n",
    "    plt.plot(epoch, acc_list)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./full_limit.csv')\n",
    "len(list(df.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df)[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "132747b86887e4ef8ae18fd8cdb3504bb0c45a42c67914925c3315afe59af0fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
